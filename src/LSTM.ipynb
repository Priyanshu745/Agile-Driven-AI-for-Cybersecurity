{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNSTMEkr/mS8+EAQgHswYE/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"OrtUKT4lU7Wx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740728819407,"user_tz":-330,"elapsed":697104,"user":{"displayName":"PRIYANSHU","userId":"14777312583550931565"}},"outputId":"08993b48-daaf-4b1f-9338-369aedb07695"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","\n","==== Training LSTM Models for Each Dataset ====\n","\n","\n","ðŸ”¹ Training on NSLKDD dataset...\n","\n","âœ… NSLKDD dataset limited to 100000 rows.\n","Epoch 1/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 44ms/step - accuracy: 0.8923 - loss: 0.2586\n","Epoch 2/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 38ms/step - accuracy: 0.9514 - loss: 0.1203\n","Epoch 3/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 38ms/step - accuracy: 0.9605 - loss: 0.0990\n","Epoch 4/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 38ms/step - accuracy: 0.9636 - loss: 0.0901\n","Epoch 5/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 38ms/step - accuracy: 0.9683 - loss: 0.0795\n","Epoch 6/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 39ms/step - accuracy: 0.9723 - loss: 0.0734\n","Epoch 7/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 38ms/step - accuracy: 0.9734 - loss: 0.0690\n","Epoch 8/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 39ms/step - accuracy: 0.9764 - loss: 0.0647\n","Epoch 9/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 38ms/step - accuracy: 0.9772 - loss: 0.0620\n","Epoch 10/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 38ms/step - accuracy: 0.9712 - loss: 0.0741\n","\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step\n","ðŸŽ¯ LSTM Accuracy for NSLKDD: 0.9772\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.98      0.98     15055\n","           1       0.98      0.98      0.98     14945\n","\n","    accuracy                           0.98     30000\n","   macro avg       0.98      0.98      0.98     30000\n","weighted avg       0.98      0.98      0.98     30000\n","\n","\n","ðŸ”¹ Training on UNSW_NB15 dataset...\n","\n","âœ… UNSW_NB15 dataset limited to 100000 rows.\n","Epoch 1/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 43ms/step - accuracy: 0.8998 - loss: 0.2237\n","Epoch 2/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 40ms/step - accuracy: 0.9996 - loss: 0.0016\n","Epoch 3/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 42ms/step - accuracy: 0.9997 - loss: 0.0010\n","Epoch 4/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 41ms/step - accuracy: 0.9999 - loss: 4.6008e-04\n","Epoch 5/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 6.2611e-05\n","Epoch 6/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 41ms/step - accuracy: 0.9999 - loss: 3.6120e-04\n","Epoch 7/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.4038e-05\n","Epoch 8/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.7639e-05\n","Epoch 9/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 42ms/step - accuracy: 0.9998 - loss: 8.2605e-04\n","Epoch 10/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.6749e-06\n","\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step\n","ðŸŽ¯ LSTM Accuracy for UNSW_NB15: 1.0000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10663\n","           1       1.00      1.00      1.00     19337\n","\n","    accuracy                           1.00     30000\n","   macro avg       1.00      1.00      1.00     30000\n","weighted avg       1.00      1.00      1.00     30000\n","\n","\n","ðŸ”¹ Training on KDDCup dataset...\n","\n","âœ… KDDCup dataset limited to 100000 rows.\n","Epoch 1/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 40ms/step - accuracy: 0.9172 - loss: 0.3511\n","Epoch 2/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 39ms/step - accuracy: 0.9950 - loss: 0.0260\n","Epoch 3/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 39ms/step - accuracy: 0.9963 - loss: 0.0193\n","Epoch 4/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 40ms/step - accuracy: 0.9966 - loss: 0.0161\n","Epoch 5/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 39ms/step - accuracy: 0.9969 - loss: 0.0137\n","Epoch 6/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 42ms/step - accuracy: 0.9978 - loss: 0.0090\n","Epoch 7/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 39ms/step - accuracy: 0.9978 - loss: 0.0089\n","Epoch 8/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 39ms/step - accuracy: 0.9981 - loss: 0.0074\n","Epoch 9/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 40ms/step - accuracy: 0.9985 - loss: 0.0063\n","Epoch 10/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 39ms/step - accuracy: 0.9981 - loss: 0.0080\n","\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step\n","ðŸŽ¯ LSTM Accuracy for KDDCup: 0.9986\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.91      0.91        11\n","           3       0.96      0.97      0.97        72\n","           4       0.00      0.00      0.00         2\n","           6       1.00      1.00      1.00      3792\n","           7       1.00      0.79      0.88        19\n","           8       1.00      1.00      1.00      6457\n","           9       0.00      0.00      0.00         1\n","          10       1.00      0.89      0.94        63\n","          11       0.98      0.96      0.97       164\n","          12       1.00      1.00      1.00     19409\n","          13       0.00      0.00      0.00         1\n","          14       0.00      0.00      0.00         9\n","\n","    accuracy                           1.00     30000\n","   macro avg       0.65      0.63      0.64     30000\n","weighted avg       1.00      1.00      1.00     30000\n","\n","\n","ðŸ”¹ Training on CICIDS2017 dataset...\n","\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["âœ… CICIDS2017 dataset limited to 100000 rows.\n","Epoch 1/10\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n","  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Epoch 2/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Epoch 3/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Epoch 4/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Epoch 5/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Epoch 6/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Epoch 7/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Epoch 8/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Epoch 9/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Epoch 10/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","\u001b[1m  4/938\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m18s\u001b[0m 20ms/step  "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (32, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step\n","ðŸŽ¯ LSTM Accuracy for CICIDS2017: 1.0000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     30000\n","\n","    accuracy                           1.00     30000\n","   macro avg       1.00      1.00      1.00     30000\n","weighted avg       1.00      1.00      1.00     30000\n","\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report\n","from google.colab import drive\n","\n","# âœ… Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# âœ… File paths\n","file_paths = [\n","    \"/content/drive/MyDrive/Datasets/NSLKDD.csv\",\n","    \"/content/drive/MyDrive/Datasets/UNSW_NB15_merged.csv\",\n","    \"/content/drive/MyDrive/Datasets/kddcup.csv\",\n","    \"/content/drive/MyDrive/Datasets/CICIDS2017.csv\"\n","]\n","dataset_names = [\"NSLKDD\", \"UNSW_NB15\", \"KDDCup\", \"CICIDS2017\"]\n","\n","# âœ… Correct target column names\n","target_columns = {\n","    \"NSLKDD\": \"anomaly\",\n","    \"UNSW_NB15\": \"label\",\n","    \"KDDCup\": \"Label\",\n","    \"CICIDS2017\": \" Label\"\n","}\n","\n","print(\"\\n==== Training LSTM Models for Each Dataset ====\\n\")\n","\n","for file, name in zip(file_paths, dataset_names):\n","    print(f\"\\nðŸ”¹ Training on {name} dataset...\\n\")\n","\n","    try:\n","        df = pd.read_csv(file, low_memory=False).dropna(axis=1, how='all')\n","    except FileNotFoundError:\n","        print(f\"âŒ Error: {file} not found. Skipping {name}.\")\n","        continue\n","\n","    # âœ… Limit dataset to 100,000 rows\n","    row_limit = 100000\n","    if len(df) > row_limit:\n","        df = df.sample(n=row_limit, random_state=42)\n","        print(f\"âœ… {name} dataset limited to {row_limit} rows.\")\n","\n","    target_column = target_columns.get(name)\n","    if target_column not in df.columns:\n","        print(f\"âš  Skipping {name}, target column '{target_column}' not found!\")\n","        continue\n","\n","    X = df.drop(columns=[target_column])\n","    y = df[target_column]\n","\n","    # âœ… Convert categorical columns to numerical\n","    for col in X.select_dtypes(include=['object']).columns:\n","        X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n","\n","    # âœ… Handle infinite and NaN values before scaling\n","    X.replace([np.inf, -np.inf], np.nan, inplace=True)\n","    X.fillna(X.median(), inplace=True)\n","\n","    # âœ… Scale features\n","    scaler = StandardScaler()\n","    X = scaler.fit_transform(X)\n","\n","    # âœ… Encode target labels\n","    label_encoder = LabelEncoder()\n","    y = label_encoder.fit_transform(y)\n","\n","    num_classes = len(np.unique(y))\n","    binary_classification = num_classes == 2  # Check if it's binary\n","\n","    if not binary_classification:\n","        y = to_categorical(y, num_classes)  # One-hot encode for multi-class\n","\n","    # âœ… Reshape input for LSTM (Samples, Time Steps, Features)\n","    X = X.reshape(X.shape[0], X.shape[1], 1)\n","\n","    # âœ… Split dataset\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","    # âœ… Define LSTM Model\n","    model = Sequential([\n","        Input(shape=(X.shape[1], 1)),  # Use Input layer for Sequential models\n","        LSTM(64, return_sequences=True),\n","        Dropout(0.2),\n","        LSTM(32),\n","        Dropout(0.2),\n","        Dense(32, activation='relu'),\n","        Dense(1 if binary_classification else num_classes, activation='sigmoid' if binary_classification else 'softmax')\n","    ])\n","\n","    # âœ… Compile Model\n","    model.compile(\n","        loss='binary_crossentropy' if binary_classification else 'categorical_crossentropy',\n","        optimizer='adam',\n","        metrics=['accuracy']\n","    )\n","\n","    # âœ… Train LSTM Model\n","    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n","\n","    # âœ… Evaluate Model\n","    y_pred = model.predict(X_test)\n","    y_pred = np.argmax(y_pred, axis=1) if not binary_classification else (y_pred > 0.5).astype(int).flatten()\n","    y_test = np.argmax(y_test, axis=1) if not binary_classification else y_test.flatten()\n","\n","    accuracy = accuracy_score(y_test, y_pred)\n","    print(f\"ðŸŽ¯ LSTM Accuracy for {name}: {accuracy:.4f}\")\n","    print(classification_report(y_test, y_pred))\n"]}]}