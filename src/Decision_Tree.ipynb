{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyORnVi7rBsp1rdqAVPUpkiq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"kFVT4hoYWCwd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740698358333,"user_tz":-330,"elapsed":100580,"user":{"displayName":"PRIYANSHU","userId":"14777312583550931565"}},"outputId":"8da2853d-3cf4-4928-9dd9-c5e3a35add7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","\n","==== Training Decision Tree Models for Each Dataset ====\n","\n","\n","🔹 Training on NSLKDD dataset...\n","\n","✅ NSLKDD dataset limited to 100000 rows.\n","🎯 Decision Tree Accuracy for NSLKDD: 0.9940\n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.99      0.99     14887\n","           1       0.99      0.99      0.99     15113\n","\n","    accuracy                           0.99     30000\n","   macro avg       0.99      0.99      0.99     30000\n","weighted avg       0.99      0.99      0.99     30000\n","\n","\n","🔹 Training on UNSW_NB15 dataset...\n","\n","✅ UNSW_NB15 dataset limited to 100000 rows.\n","🎯 Decision Tree Accuracy for UNSW_NB15: 1.0000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10805\n","           1       1.00      1.00      1.00     19195\n","\n","    accuracy                           1.00     30000\n","   macro avg       1.00      1.00      1.00     30000\n","weighted avg       1.00      1.00      1.00     30000\n","\n","\n","🔹 Training on KDDCup dataset...\n","\n","✅ KDDCup dataset limited to 100000 rows.\n","🎯 Decision Tree Accuracy for KDDCup: 0.9988\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.95      0.98        21\n","           1       1.00      1.00      1.00         1\n","           2       1.00      0.00      0.00         1\n","           3       1.00      0.95      0.98        84\n","           4       0.00      1.00      0.00         0\n","           6       1.00      1.00      1.00      3795\n","           7       0.77      0.88      0.82        26\n","           8       1.00      1.00      1.00      6384\n","           9       1.00      0.00      0.00         1\n","          10       1.00      0.92      0.96        73\n","          11       0.93      0.98      0.95       135\n","          12       1.00      1.00      1.00     19466\n","          13       1.00      1.00      1.00         1\n","          14       0.60      0.75      0.67        12\n","\n","    accuracy                           1.00     30000\n","   macro avg       0.88      0.82      0.74     30000\n","weighted avg       1.00      1.00      1.00     30000\n","\n","\n","🔹 Training on CICIDS2017 dataset...\n","\n","✅ CICIDS2017 dataset limited to 100000 rows.\n","🎯 Decision Tree Accuracy for CICIDS2017: 1.0000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     30000\n","\n","    accuracy                           1.00     30000\n","   macro avg       1.00      1.00      1.00     30000\n","weighted avg       1.00      1.00      1.00     30000\n","\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.metrics import accuracy_score, classification_report\n","from google.colab import drive\n","\n","# ✅ Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# ✅ File paths\n","file_paths = [\n","    \"/content/drive/MyDrive/Datasets/NSLKDD.csv\",\n","    \"/content/drive/MyDrive/Datasets/UNSW_NB15_merged.csv\",\n","    \"/content/drive/MyDrive/Datasets/kddcup.csv\",\n","    \"/content/drive/MyDrive/Datasets/CICIDS2017.csv\"\n","]\n","dataset_names = [\"NSLKDD\", \"UNSW_NB15\", \"KDDCup\", \"CICIDS2017\"]\n","\n","# ✅ Correct target column names\n","target_columns = {\n","    \"NSLKDD\": \"anomaly\",\n","    \"UNSW_NB15\": \"label\",\n","    \"KDDCup\": \"Label\",  # Verify correct column name\n","    \"CICIDS2017\": \" Label\"\n","}\n","\n","print(\"\\n==== Training Decision Tree Models for Each Dataset ====\\n\")\n","\n","for file, name in zip(file_paths, dataset_names):\n","    print(f\"\\n🔹 Training on {name} dataset...\\n\")\n","\n","    try:\n","        df = pd.read_csv(file, low_memory=False).dropna(axis=1, how='all')\n","    except FileNotFoundError:\n","        print(f\"❌ Error: {file} not found. Skipping {name}.\")\n","        continue\n","\n","    # ✅ Limit dataset to 100,000 rows\n","    row_limit = 100000\n","    if len(df) > row_limit:\n","        df = df.sample(n=row_limit, random_state=42)\n","        print(f\"✅ {name} dataset limited to {row_limit} rows.\")\n","\n","    target_column = target_columns.get(name)\n","    if target_column not in df.columns:\n","        print(f\"⚠ Skipping {name}, target column '{target_column}' not found!\")\n","        continue\n","\n","    X = df.drop(columns=[target_column])\n","    y = df[target_column]\n","\n","    # ✅ Encode categorical features\n","    for col in X.select_dtypes(include=['object']).columns:\n","        X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n","\n","    # ✅ Convert X to float32 & handle NaN/Inf\n","    X = X.astype(np.float32)\n","    X.replace([np.inf, -np.inf], np.nan, inplace=True)\n","    X.fillna(X.mean(), inplace=True)\n","\n","    # ✅ Apply Standard Scaling\n","    X = StandardScaler().fit_transform(X)\n","    y = LabelEncoder().fit_transform(y)\n","\n","    # ✅ Split data (70% train, 30% test)\n","    split = int(0.7 * len(X))\n","    X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n","\n","    # ✅ Train Decision Tree Model\n","    clf = DecisionTreeClassifier(random_state=42)\n","    clf.fit(X_train, y_train)\n","\n","    # ✅ Predictions\n","    y_pred = clf.predict(X_test)\n","\n","    # ✅ Model Evaluation\n","    accuracy = accuracy_score(y_test, y_pred)\n","    print(f\"🎯 Decision Tree Accuracy for {name}: {accuracy:.4f}\")\n","    print(classification_report(y_test, y_pred, zero_division=1))  # ✅ Fix undefined precision warnings\n"]}]}