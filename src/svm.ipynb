{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"_Rps3z6YEOdB"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","\n","==== Training SVM Models for Each Dataset ====\n","\n","\n","🔹 Training on NSLKDD dataset...\n","\n","✅ NSLKDD dataset limited to 100,000 rows.\n","📊 Class distribution before split: Counter({0: 50001, 1: 49999})\n","📊 Class distribution after split: Counter({0: 35001, 1: 34999})\n","✅ Applied SMOTE to balance dataset.\n","🎯 SVM Accuracy for NSLKDD: 0.9780\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.98      0.98     15000\n","           1       0.98      0.98      0.98     15000\n","\n","    accuracy                           0.98     30000\n","   macro avg       0.98      0.98      0.98     30000\n","weighted avg       0.98      0.98      0.98     30000\n","\n","\n","🔹 Training on UNSW_NB15 dataset...\n","\n","✅ UNSW_NB15 dataset limited to 100,000 rows.\n","📊 Class distribution before split: Counter({1: 63917, 0: 36083})\n","📊 Class distribution after split: Counter({1: 44742, 0: 25258})\n","✅ Applied SMOTE to balance dataset.\n","🎯 SVM Accuracy for UNSW_NB15: 0.9936\n","              precision    recall  f1-score   support\n","\n","           0       0.99      1.00      0.99     10825\n","           1       1.00      0.99      1.00     19175\n","\n","    accuracy                           0.99     30000\n","   macro avg       0.99      0.99      0.99     30000\n","weighted avg       0.99      0.99      0.99     30000\n","\n","\n","🔹 Training on KDDCup dataset...\n","\n","✅ KDDCup dataset limited to 100,000 rows.\n","📊 Class distribution before split: Counter({12: 65043, 8: 21302, 6: 12519, 11: 495, 3: 260, 10: 207, 7: 74, 0: 53, 14: 30, 13: 9, 4: 2, 1: 2, 5: 2, 2: 1, 9: 1})\n","📊 Class distribution after split: Counter({12: 45634, 8: 14845, 6: 8727, 11: 331, 3: 188, 10: 144, 7: 55, 0: 42, 14: 21, 13: 8, 1: 2, 5: 2, 2: 1})\n","⚠ Skipping SMOTE due to insufficient class samples.\n","🎯 SVM Accuracy for KDDCup: 0.9987\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        11\n","           3       0.99      0.97      0.98        72\n","           4       0.00      0.00      0.00         2\n","           6       1.00      1.00      1.00      3792\n","           7       0.86      0.95      0.90        19\n","           8       1.00      1.00      1.00      6457\n","           9       0.00      0.00      0.00         1\n","          10       0.98      0.98      0.98        63\n","          11       0.99      0.99      0.99       164\n","          12       1.00      1.00      1.00     19409\n","          13       1.00      1.00      1.00         1\n","          14       0.28      0.89      0.42         9\n","\n","    accuracy                           1.00     30000\n","   macro avg       0.76      0.82      0.77     30000\n","weighted avg       1.00      1.00      1.00     30000\n","\n","\n","🔹 Training on CICIDS2017 dataset...\n","\n","✅ CICIDS2017 dataset limited to 100,000 rows.\n","📊 Class distribution before split: Counter({0: 100000})\n","❌ Skipping training for CICIDS2017 (Only one class present: 0).\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.svm import SVC\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.model_selection import train_test_split\n","from imblearn.over_sampling import SMOTE\n","from collections import Counter\n","from google.colab import drive\n","\n","# ✅ Mount Google Drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# ✅ File paths\n","file_paths = [\n","    \"/content/drive/MyDrive/Datasets/NSLKDD.csv\",\n","    \"/content/drive/MyDrive/Datasets/UNSW_NB15_merged.csv\",\n","    \"/content/drive/MyDrive/Datasets/kddcup.csv\",\n","    \"/content/drive/MyDrive/Datasets/CICIDS2017.csv\"\n","]\n","dataset_names = [\"NSLKDD\", \"UNSW_NB15\", \"KDDCup\", \"CICIDS2017\"]\n","\n","# ✅ Correct target column names\n","target_columns = {\n","    \"NSLKDD\": \"anomaly\",\n","    \"UNSW_NB15\": \"label\",\n","    \"KDDCup\": \"Label\",\n","    \"CICIDS2017\": \" Label\"\n","}\n","\n","print(\"\\n==== Training SVM Models for Each Dataset ====\\n\")\n","\n","for file, name in zip(file_paths, dataset_names):\n","    print(f\"\\n🔹 Training on {name} dataset...\\n\")\n","\n","    try:\n","        df = pd.read_csv(file, low_memory=False).dropna(axis=1, how='all')\n","    except FileNotFoundError:\n","        print(f\"❌ Error: {file} not found. Skipping {name}.\")\n","        continue\n","\n","    # ✅ Limit dataset to 100,000 rows\n","    if len(df) \u003e 100000:\n","        df = df.sample(n=100000, random_state=42)\n","        print(f\"✅ {name} dataset limited to 100,000 rows.\")\n","\n","    target_column = target_columns.get(name)\n","    if target_column not in df.columns:\n","        print(f\"⚠ Skipping {name}, target column '{target_column}' not found!\")\n","        continue\n","\n","    X = df.drop(columns=[target_column])\n","    y = df[target_column]\n","\n","    # ✅ Convert categorical columns to numerical\n","    label_encoders = {}\n","    for col in X.select_dtypes(include=['object']).columns:\n","        le = LabelEncoder()\n","        X[col] = le.fit_transform(X[col].astype(str))\n","        label_encoders[col] = le\n","\n","    # ✅ Handle infinite and NaN values\n","    X.replace([np.inf, -np.inf], np.nan, inplace=True)\n","    for col in X.columns:\n","        if X[col].isna().sum() \u003e 0:\n","            if X[col].dtype == 'object':\n","                X[col].fillna(X[col].mode()[0], inplace=True)\n","            else:\n","                X.fillna({col: X[col].median()}, inplace=True)  # ✅ Fix FutureWarning\n","\n","    # ✅ Scale features\n","    X = StandardScaler().fit_transform(X)\n","    y = LabelEncoder().fit_transform(y)\n","\n","    # ✅ Check class distribution\n","    class_counts = Counter(y)\n","    print(f\"📊 Class distribution before split: {class_counts}\")\n","\n","    # ✅ Handle single-class datasets (Avoids crash)\n","    if len(class_counts) == 1:\n","        print(f\"❌ Skipping training for {name} (Only one class present: {list(class_counts.keys())[0]}).\")\n","        continue\n","\n","    # ✅ Handle case where any class has \u003c2 samples (avoiding stratify error)\n","    min_class_count = min(class_counts.values())\n","    stratify_option = y if min_class_count \u003e= 2 else None\n","\n","    # ✅ Train-Test Split (Avoids stratify error)\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=0.3, random_state=42, stratify=stratify_option\n","    )\n","\n","    print(f\"📊 Class distribution after split: {Counter(y_train)}\")\n","\n","    # ✅ Handle datasets with only 1 class in training\n","    if len(set(y_train)) == 1:\n","        print(f\"❌ Skipping training for {name} (Only 1 class in training data).\")\n","        continue\n","\n","    # ✅ Apply SMOTE only if every class has at least 6 samples\n","    if all(count \u003e= 6 for count in Counter(y_train).values()):\n","        smote = SMOTE(random_state=42)\n","        X_train, y_train = smote.fit_resample(X_train, y_train)\n","        print(\"✅ Applied SMOTE to balance dataset.\")\n","    else:\n","        print(\"⚠ Skipping SMOTE due to insufficient class samples.\")\n","\n","    # ✅ Train SVM Model with Class Weighting\n","    clf = SVC(kernel=\"rbf\", class_weight=\"balanced\", random_state=42)\n","    clf.fit(X_train, y_train)\n","\n","    # ✅ Predictions\n","    y_pred = clf.predict(X_test)\n","\n","    # ✅ Model Evaluation\n","    accuracy = accuracy_score(y_test, y_pred)\n","    print(f\"🎯 SVM Accuracy for {name}: {accuracy:.4f}\")\n","    print(classification_report(y_test, y_pred, zero_division=0))\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPsEAnhW6kMI4jw7h2O6BHm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}