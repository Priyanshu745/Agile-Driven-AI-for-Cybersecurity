{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOAEXkupst/yM05FCHQu50+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"gYo0KCDcVQhU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740699320680,"user_tz":-330,"elapsed":894671,"user":{"displayName":"PRIYANSHU","userId":"14777312583550931565"}},"outputId":"dda5e0fd-3aea-46c0-993a-edc7ceb8a4e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","\n","==== Training KMeans Models for Each Dataset ====\n","\n","\n","ðŸ”¹ Training on NSLKDD dataset...\n","\n","âœ… NSLKDD dataset limited to 100000 rows.\n","âœ… KMeans Silhouette Score for NSLKDD: 0.3270\n","\n","ðŸ”¹ Training on UNSW_NB15 dataset...\n","\n","âœ… UNSW_NB15 dataset limited to 100000 rows.\n","âœ… KMeans Silhouette Score for UNSW_NB15: 0.2636\n","\n","ðŸ”¹ Training on KDDCup dataset...\n","\n","âœ… KDDCup dataset limited to 100000 rows.\n","âœ… KMeans Silhouette Score for KDDCup: 0.7890\n","\n","ðŸ”¹ Training on CICIDS2017 dataset...\n","\n","âœ… CICIDS2017 dataset limited to 100000 rows.\n","âœ… KMeans Silhouette Score for CICIDS2017: 0.1920\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.cluster import KMeans\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.metrics import silhouette_score\n","from google.colab import drive\n","\n","# âœ… Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# âœ… File paths\n","file_paths = [\n","    \"/content/drive/MyDrive/Datasets/NSLKDD.csv\",\n","    \"/content/drive/MyDrive/Datasets/UNSW_NB15_merged.csv\",\n","    \"/content/drive/MyDrive/Datasets/kddcup.csv\",\n","    \"/content/drive/MyDrive/Datasets/CICIDS2017.csv\"\n","]\n","dataset_names = [\"NSLKDD\", \"UNSW_NB15\", \"KDDCup\", \"CICIDS2017\"]\n","\n","# âœ… Correct target column names\n","target_columns = {\n","    \"NSLKDD\": \"anomaly\",\n","    \"UNSW_NB15\": \"label\",\n","    \"KDDCup\": \"Label\",  # Verify correct column name\n","    \"CICIDS2017\": \" Label\"\n","}\n","\n","print(\"\\n==== Training KMeans Models for Each Dataset ====\\n\")\n","\n","for file, name in zip(file_paths, dataset_names):\n","    print(f\"\\nðŸ”¹ Training on {name} dataset...\\n\")\n","\n","    try:\n","        df = pd.read_csv(file, low_memory=False).dropna(axis=1, how='all')\n","    except FileNotFoundError:\n","        print(f\"âŒ Error: {file} not found. Skipping {name}.\")\n","        continue\n","\n","    # âœ… Limit dataset to 100,000 rows\n","    row_limit = 100000\n","    if len(df) > row_limit:\n","        df = df.sample(n=row_limit, random_state=42)\n","        print(f\"âœ… {name} dataset limited to {row_limit} rows.\")\n","\n","    target_column = target_columns.get(name)\n","    if target_column not in df.columns:\n","        print(f\"âš  Skipping {name}, target column '{target_column}' not found!\")\n","        continue\n","\n","    X = df.drop(columns=[target_column])\n","\n","    # âœ… Encode categorical features\n","    for col in X.select_dtypes(include=['object']).columns:\n","        X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n","\n","    # âœ… Convert X to float32 & handle NaN/Inf\n","    X = X.astype(np.float32)\n","    X.replace([np.inf, -np.inf], np.nan, inplace=True)\n","    X.fillna(X.mean(), inplace=True)\n","\n","    # âœ… Apply Standard Scaling\n","    X = StandardScaler().fit_transform(X)\n","\n","    # âœ… Train KMeans Model\n","    kmeans = KMeans(n_clusters=2, random_state=42)\n","    kmeans.fit(X)\n","\n","    # âœ… Evaluate Clustering\n","    score = silhouette_score(X, kmeans.labels_)\n","    print(f\"âœ… KMeans Silhouette Score for {name}: {score:.4f}\")\n"]}]}